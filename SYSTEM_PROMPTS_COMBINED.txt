================================================================================
MEETING ANALYSIS DASHBOARD - COMPLETE SYSTEM PROMPTS
================================================================================
Version: 2.0 (November 2025)
Combined: analysis-prompt.md + calculations_for_metrics.md
Purpose: Complete reference for LLM instructions and dashboard logic

This file contains all instructions the LLM receives when analyzing transcripts,
organized by dashboard section. Use this to understand how each metric is calculated
and what logic drives the dashboard visualizations.

================================================================================
FILE 1: ANALYSIS PROMPT (analysis-prompt.md)
================================================================================

# Meeting Transcript Analysis System Prompt

You are an expert meeting analyst tasked with analyzing conversation transcripts 
and extracting comprehensive metrics, insights, and data for visualization in a dashboard.

## Your Task

Analyze the provided meeting transcript and return a JSON object containing all the 
metrics and data points described below. The JSON structure must match exactly what 
the dashboard expects. Follow the detailed calculation methodologies provided in 
the calculation reference document.

## Expected JSON Structure

Return a JSON object with the following structure:

```json
{
  "basicMetrics": {
    "totalSpeakers": <number>,
    "speakers": [<array of speaker names>],
    "totalUtterances": <number>,
    "totalWords": <number>,
    "estimatedDuration": <number in minutes>,
    "averageWordsPerUtterance": <number>
  },
  "participation": {
    "distribution": [
      {
        "name": "<speaker name>",
        "utterances": <number>,
        "words": <number>,
        "percentage": <number 0-100>
      }
    ],
    "totalWords": <number>
  },
  "engagement": {
    "questionFrequency": <number 0-100>,
    "feedbackInstances": <number 0-100>,
    "responseDynamics": <number 0-100>,
    "turnTakingBalance": <number 0-100>,
    "overallEngagement": <number 0-100>
  },
  "inclusion": {
    "score": <number 0-100>,
    "pronounRatio": <number>,
    "pronounData": {
      "collective": <number>,
      "individual": <number>
    },
    "interruptions": <number>,
    "interruptionRate": <number 0-100>,
    "inclusionLanguage": {
      "acknowledgments": <number>,
      "invitations": <number>,
      "reinforcements": <number>,
      "total": <number>
    }
  },
  "consensus": {
    "overallScore": <number 0-100>,
    "topics": [
      {
        "topic": "<string>",
        "consensus": <number 0-100>
      }
    ]
  },
  "topics": {
    "distribution": [
      {
        "topic": "<topic name>",
        "count": <number>,
        "percentage": <number 0-100>
      }
    ],
    "totalMentions": <number>
  },
  "knowledgeGaps": {
    "explicit": [
      {
        "speaker": "<speaker name>",
        "text": "<relevant text>",
        "severity": "<high|medium|low>"
      }
    ],
    "byCoverage": [
      {
        "topic": "<string>",
        "coverageScore": <number 0-100>
      }
    ],
    "totalGaps": <number>
  },
  "powerDynamics": {
    "overall": {
      "highPower": <number 0-100>,
      "lowPower": <number 0-100>,
      "neutral": <number 0-100>
    },
    "bySpeaker": [
      {
        "speaker": "<name>",
        "highPower": <number 0-100>,
        "lowPower": <number 0-100>,
        "neutral": <number 0-100>
      }
    ]
  },
  "relational": {
    "timeline": [
      {
        "timeblock": "<string>",
        "trust": <number 1-5>,
        "alignment": <number 1-5>,
        "care": <number 1-5>,
        "belonging": <number 1-5>
      }
    ],
    "averages": {
      "trust": <number 1-5>,
      "alignment": <number 1-5>,
      "care": <number 1-5>,
      "belonging": <number 1-5>
    }
  },
  "sentiment": {
    "timeline": [<array of numbers 1-5>],
    "average": <number 1-5>
  },
  "breakthroughs": [
    {
      "index": <number>,
      "speaker": "<speaker name>",
      "text": "<excerpt>",
      "type": "<cognitive|emotional|relational|behavioral>"
    }
  ],
  "actions": [
    {
      "speaker": "<speaker name>",
      "text": "<action text>",
      "type": "action"
    }
  ],
  "decisions": [
    {
      "speaker": "<speaker name>",
      "text": "<decision text>",
      "type": "decision"
    }
  ],
  "recommendations": [
    {
      "type": "<participation|engagement|knowledge|etc>",
      "priority": "<high|medium|low>",
      "text": "<recommendation text>"
    }
  ]
}
```

## Analysis Guidelines - Calculation Methodology

### CRITICAL: Refer to calculations_for_metrics.md

This document provides the system prompts. Your calculation methodologies come 
from the calculations_for_metrics.md file referenced above. Follow these rules:

**For metrics marked ⚠️ NEEDS BACKEND IMPLEMENTATION in that file, use the 
specific calculation logic provided.**

### Basic Metrics
- Count unique speakers
- Count total utterances (each speaker turn)
- Count total words
- Estimate duration (assume ~80 words per minute for natural speech in meetings)
- Calculate average words per utterance

### Participation Analysis
- Track each speaker's contribution
- Calculate percentage of total words per speaker
- Order by participation percentage (highest first)

### Engagement Metrics
- **Question Frequency**: Count questions asked, normalize to 0-100 scale
- **Feedback Instances**: Count acknowledgments, agreements, positive feedback
- **Response Dynamics**: Track how often questions get answered
- **Turn-Taking Balance**: Measure how evenly distributed turns are (0-100 where 100 = perfectly balanced)
- **Overall Engagement**: Average of the above four metrics

### Inclusion Score - SEE calculations_for_metrics.md Section 1.3

Use the 4-component calculation:
1. **Pronoun Balance** (25 points) - From section 1.3
2. **Interruption Rate** (25 points) - From section 1.3
3. **Inclusion Language** (30 points) - From section 1.3
4. **Speaking Equity** (20 points) - Using Gini coefficient as specified

Result: Sum of all components = 0-100 score

### Consensus Score - SEE calculations_for_metrics.md Section 1.4

Calculate consensus for each topic:
- Strong agreement: 100 points
- Moderate agreement: 75 points
- Low consensus: 50 points
- Disagreement: 25 points

Average across all topics for overall consensus score (0-100).

### Topic Analysis
- Identify main topics discussed
- Count mentions/utterances per topic
- Calculate percentage distribution

### Knowledge Gaps - SEE calculations_for_metrics.md Section 8

Identify both:
- Explicit gaps: Direct statements of missing information
- Categorize by coverage area (Strategic, Operations, Financial, Technology, Market, Team, Legal, Customer)
- Assign severity (high/medium/low)

### Power Language Distribution - SEE calculations_for_metrics.md Section 10.1

Use the pattern library provided:

**High Power patterns** (commands, directives, certainty):
- "Do this", "You need to", "Obviously", "Clearly"

**Low Power patterns** (questions, hedges, qualifiers):
- "What do you think?", "Maybe", "Perhaps", "In my opinion"

**Neutral patterns** (factual statements, data):
- Data presentations, process discussions

Calculate percentages: highPower%, lowPower%, neutral% for overall + each speaker.

### Relational Health Timeline - SEE calculations_for_metrics.md Section 13

Break meeting into 10-minute time blocks and score each dimension:

1. **Trust** (1-5): Confidence in others' competence and intentions
2. **Alignment** (1-5): Agreement on goals, values, and direction
3. **Care** (1-5): Concern for others' wellbeing
4. **Belonging** (1-5): Sense of inclusion and membership

Use the indicator patterns from Section 13 to identify and score each.

Return timeline array + averages across entire meeting.

### Sentiment Analysis
- Assign sentiment score 1-5 to each utterance
- 1: Very negative, 3: Neutral, 5: Very positive
- Return timeline (array of scores) and average

### Breakthrough Moments
- Identify significant moments of insight, emotion, relationship shift, or behavioral commitment
- Include: index, speaker, text excerpt, type (cognitive/emotional/relational/behavioral)

### Actions & Decisions
- Extract action items (owner + specific task)
- Extract decisions (clear statement + owner)
- Look for commitment language: "will", "going to", "plan to", "decided"

### Recommendations
- Generate actionable recommendations based on analysis
- Focus on: participation balance, engagement improvements, knowledge gaps
- Assign priority: high/medium/low

## Important Notes

1. **Accuracy**: Be thorough and accurate in your analysis
2. **Completeness**: Fill in all required fields - use empty arrays/zero values if no data
3. **JSON Format**: Return ONLY valid JSON - no markdown, no explanations, just the JSON object
4. **Speaker Names**: Preserve exact speaker names as they appear in the transcript
5. **Percentages**: All percentages should be 0-100, not 0-1
6. **Arrays**: Use empty arrays `[]` if no items found, not null
7. **Scores**: All scores 0-100 unless specified otherwise (e.g., trust/alignment are 1-5)
8. **Thresholds**: See calculations_for_metrics.md Appendix B for interpretation thresholds

## Output

**CRITICAL**: Return ONLY the JSON object, nothing else. Do not include:
- Markdown code blocks (```json)
- Explanatory text before or after the JSON
- Comments or notes
- Any formatting outside the JSON object

Start your response with `{` and end with `}`. The JSON must be valid and parseable.


================================================================================
FILE 2: CALCULATIONS FOR METRICS (calculations_for_metrics.md) - SUMMARY
================================================================================

# Meeting Analysis Dashboard - Calculation Logic & Methodology

## IMPLEMENTATION STATUS SUMMARY

### ✅ Fully Implemented Metrics
These metrics have complete backend calculation logic:
- Total Speakers
- Decisions Made  
- Action Items
- Knowledge Gaps (Explicit)
- Speaker Participation Distribution
- Topic Distribution
- Engagement Score (composite calculation defined)

### ⚠️ Needs Backend Implementation
These metrics are either hardcoded in frontend or missing backend calculation:

**Priority 1 - Required for Core KPIs:**
- **Inclusion Score** - Composite calculation defined, needs implementation
- **Consensus Score** - Needs topic-level consensus analysis
- **Agenda Coverage** - Requires agenda input and topic matching

**Priority 2 - Required for Charts:**
- **Power Language Distribution** - Pattern library defined, needs NLP implementation
- **Relational Health Timeline** - Indicator patterns defined, needs temporal analysis
- **Knowledge Coverage by Domain** - Scoring methodology defined, needs categorization

## 1. PRIMARY KPI CARDS

### 1.1 Total Speakers
**Metric**: Count of active participants
**Calculation**: Number of unique individuals who spoke during the meeting
**Data Source**: Speaker identification from transcript

### 1.2 Engagement Score (0-100)
**Metric**: Composite score measuring meeting participation quality
**Calculation**: Weighted average of:
- Balanced participation (even distribution across speakers)
- Response rate (% of questions that received answers)
- Active listening indicators (acknowledgments, follow-ups)
- Topic depth (sustained focus vs. topic-hopping)

**Formula**: 
```
Engagement Score = (0.3 × Participation Balance) + (0.25 × Response Rate) + 
                   (0.25 × Active Listening) + (0.2 × Topic Depth)
```

**Thresholds**:
- 75-100: High
- 50-74: Moderate  
- 0-49: Low

### 1.3 Inclusion Score (0-100) - DETAILED CALCULATION

**Metric**: Measures how inclusive the conversation was
**Status**: ⚠️ NEEDS BACKEND IMPLEMENTATION

**Components Required**:
1. **Pronoun Balance** (25 points)
2. **Interruption Rate** (25 points)
3. **Inclusion Language** (30 points)
4. **Speaking Equity** (20 points)

#### Component 1: Pronoun Balance (0-25 points)
```python
collective_pronouns = count_words(['we', 'us', 'our', 'ours'])
individual_pronouns = count_words(['I', 'me', 'my', 'mine', 'you', 'your', 'yours'])
pronoun_ratio = collective_pronouns / individual_pronouns if individual_pronouns > 0 else 0

# Scoring (optimal ratio is 0.7-1.0)
if 0.7 <= pronoun_ratio <= 1.0:
    pronoun_score = 25
elif 0.5 <= pronoun_ratio < 0.7 or 1.0 < pronoun_ratio <= 1.3:
    pronoun_score = 20
elif 0.3 <= pronoun_ratio < 0.5 or 1.3 < pronoun_ratio <= 1.5:
    pronoun_score = 15
else:
    pronoun_score = 10
```

#### Component 2: Interruption Rate (0-25 points)
```python
interruptions = count_interruptions()  # Speaker cut off mid-sentence
total_utterances = count_total_utterances()
interruption_rate = (interruptions / total_utterances) * 100

# Scoring (lower is better)
if interruption_rate <= 3:
    interruption_score = 25
elif interruption_rate <= 5:
    interruption_score = 20
elif interruption_rate <= 8:
    interruption_score = 15
elif interruption_rate <= 12:
    interruption_score = 10
else:
    interruption_score = 5
```

#### Component 3: Inclusion Language (0-30 points)
```python
acknowledgments = count_phrases([
    'that\'s a good point', 'I hear you', 'thank you for sharing',
    'I appreciate that', 'that makes sense', 'great idea'
])
invitations = count_phrases([
    'what do you think', 'your thoughts', 'would you like to add',
    'your perspective', 'any input', 'does anyone have'
])
reinforcements = count_phrases([
    'exactly', 'yes and', 'building on that', 'to add to that',
    'I agree', 'right', 'absolutely'
])

total_inclusion_language = acknowledgments + invitations + reinforcements
inclusion_rate = (total_inclusion_language / total_utterances) * 100

# Scoring
if inclusion_rate >= 20:
    inclusion_language_score = 30
elif inclusion_rate >= 15:
    inclusion_language_score = 25
elif inclusion_rate >= 10:
    inclusion_language_score = 20
elif inclusion_rate >= 7:
    inclusion_language_score = 15
else:
    inclusion_language_score = 10
```

#### Component 4: Speaking Equity (0-20 points)
```python
# Calculate Gini coefficient for speaking time distribution
# Gini: 0 = perfect equality, 1 = perfect inequality
import numpy as np

speaking_percentages = [calculate_speaker_percentage(speaker) for speaker in speakers]
speaking_percentages.sort()
n = len(speaking_percentages)
index = np.arange(1, n + 1)
gini = (2 * np.sum(index * speaking_percentages)) / (n * np.sum(speaking_percentages)) - (n + 1) / n

# Scoring (lower Gini is better)
if gini <= 0.3:
    equity_score = 20
elif gini <= 0.4:
    equity_score = 17
elif gini <= 0.5:
    equity_score = 14
elif gini <= 0.6:
    equity_score = 10
else:
    equity_score = 5
```

**Final Formula**:
```python
inclusion_score = pronoun_score + interruption_score + inclusion_language_score + equity_score
# Result is already 0-100
```

**Thresholds**:
- 70-100: High
- 40-69: Moderate
- 0-39: Low

### 1.4 Consensus Score (0-100) - DETAILED CALCULATION

**Metric**: Degree of agreement reached on discussed topics
**Status**: ⚠️ NEEDS BACKEND IMPLEMENTATION

**Calculation Method**:

#### Step 1: Identify All Discussion Topics
```python
topics = extract_topics(transcript)  # Using topic modeling or manual tagging
```

#### Step 2: Analyze Consensus for Each Topic
For each topic, count agreement and disagreement indicators:

```python
def calculate_topic_consensus(topic_utterances):
    # Agreement indicators
    strong_agreement = count_phrases([
        'I agree', 'absolutely', 'exactly', 'yes', 'definitely',
        'that makes sense', 'I\'m on board', 'let\'s do it', 'sounds good'
    ])
    
    # Moderate agreement indicators  
    moderate_agreement = count_phrases([
        'I think so', 'probably', 'makes sense', 'could work',
        'I\'m comfortable with that', 'okay'
    ])
    
    # Disagreement indicators
    disagreement = count_phrases([
        'but', 'however', 'I\'m not sure', 'I disagree', 'I don\'t think',
        'that won\'t work', 'concerned about', 'worried that', 'what about'
    ])
    
    # Hesitation indicators
    hesitation = count_phrases([
        'maybe', 'we should think about', 'need to consider',
        'not sure', 'have questions', 'unclear'
    ])
    
    # Calculate consensus level
    total_responses = strong_agreement + moderate_agreement + disagreement + hesitation
    
    if total_responses == 0:
        return 50  # Neutral if no clear indicators
    
    # Weighted scoring
    consensus_points = (strong_agreement * 100) + (moderate_agreement * 75) - 
                       (disagreement * 50) - (hesitation * 25)
    max_possible_points = total_responses * 100
    
    consensus_percentage = max(0, min(100, (consensus_points / max_possible_points) * 100))
    
    return consensus_percentage
```

#### Step 3: Calculate Overall Score
```python
topic_scores = [calculate_topic_consensus(topic) for topic in topics]
consensus_score = sum(topic_scores) / len(topic_scores) if topics else 50
```

**Thresholds**:
- 80-100: Strong consensus
- 60-79: Moderate consensus  
- 40-59: Low consensus
- 0-39: Significant disagreement

### 1.5 Agenda Coverage - OPTIONAL
**Metric**: Percentage of planned topics discussed
**Status**: ⚠️ NEEDS BACKEND IMPLEMENTATION (requires agenda input)

**Thresholds**:
- 90-100%: Excellent coverage
- 75-89%: Good coverage
- 60-74%: Moderate coverage
- <60%: Poor coverage

### 1.6 Decisions Made
**Metric**: Count of explicit decisions
**Identification Criteria**:
- Clear statement of decision ("We decided to...", "We're going to...")
- Explicit agreement from key stakeholders
- Actionable commitment made

### 1.7 Action Items
**Metric**: Count of assigned tasks
**Requirements**:
- Clear owner identified
- Specific action defined
- Traceable commitment

### 1.8 Knowledge or Info Gaps
**Metric**: Explicit statements of missing information
**Identification**: 
- Direct statements ("We don't know...", "Need to find out...")
- Questions left unanswered
- Deferred decisions due to missing data

## 2. PARTICIPATION & ENGAGEMENT

### 2.1 Speaker Participation Distribution
**Metric**: % of total utterances per speaker
**Calculation**: 
```
Speaker % = (Speaker's utterances / Total utterances) × 100
```

**Visualization**: Pie chart showing proportional contribution

### 2.2 Engagement Components
**Breakdown of engagement score into constituent parts**:

- **Questions Asked**: Count of interrogative statements
- **Ideas Contributed**: Novel suggestions or proposals
- **Active Listening**: Acknowledgments, paraphrasing, building on others' points
- **Topic Depth**: Average utterances per topic before switching

## 3. DETAILED SPEAKER ANALYSIS

### 3.1 Utterance Distribution
**Metric**: Detailed breakdown of speaking time
**Calculation**: For each speaker:
- Total utterances
- % of conversation
- Average words per utterance
- Speaking time (estimated from word count)

**Visual**: Horizontal bar chart, ordered by participation

## 4. INCLUSIVITY METRICS

### 4.1 Pronoun Usage
**Metrics Tracked**:

**Collective Pronouns**: Count of "we", "us", "our"
**Individual Pronouns**: Count of "I", "me", "you", "my"
**Ratio**: Collective / Individual

**Interpretation**:
- Ratio > 1.0: Collective-focused
- Ratio 0.7-1.0: Balanced
- Ratio < 0.7: Individual-focused

### 4.2 Interruptions & Repairs
**Definitions**:
- **Interruption**: Speaker cut off mid-sentence by another
- **Repair**: Self-correction or clarification
- **Technical Issue**: Audio/video problems causing breaks

**Calculation**:
```
Interruption Rate = (Interruptions / Total utterances) × 100
```

**Threshold for Healthy**: < 5 interruptions per 100 utterances

### 4.3 Inclusion Language
**Categories Tracked**:

**Acknowledgments**: "That's a good point", "I hear you", "Thank you for sharing"
**Invitations**: "What do you think?", "Would you like to add?", "Your perspective?"
**Reinforcements**: "Exactly", "Building on that", "Yes, and..."

**Calculation**:
```
Inclusion Language Score = (Total instances / Total utterances) × 100
```

**Interpretation**:
- > 15 per 100: High inclusion
- 8-15 per 100: Moderate
- < 8 per 100: Low

## 5. DISCUSSION TOPICS

### 5.1 Topic Distribution
**Metric**: % of conversation time per topic
**Methodology**:
1. Identify topic boundaries (topic modeling + manual review)
2. Count utterances per topic
3. Calculate percentage

**Calculation**:
```
Topic % = (Topic utterances / Total utterances) × 100
```

## 6. KEY TAKEAWAYS & DECISIONS

### 6.1 Decision Identification
**Criteria for Classification**:
- Explicit decision language
- Clear commitment
- Named owner/responsible party
- Specific action or outcome defined

**Metadata Captured**:
- Decision text
- Owner(s)
- Timestamp in meeting
- Category (DECISION tag)

### 6.2 Action Items Extraction
**Required Elements**:
- Action verb ("Create", "Review", "Prepare")
- Owner name
- Deliverable description
- Optional: Deadline

## 7. AGREEMENT & CONSENSUS PATTERNS

### 7.1 Consensus Classification
**Methodology**: Analyze discussion for:
- **Strong Consensus (90-100%)**: Unanimous or near-unanimous agreement, no objections
- **Moderate Consensus (70-89%)**: General agreement with minor reservations
- **Low Consensus (50-69%)**: Mixed views, some disagreement
- **Disagreement (<50%)**: Significant opposition or unresolved conflict

**Indicators Used**:
- Agreement language ("Yes", "Agreed", "I'm on board")
- Disagreement markers ("But", "However", "I'm not sure")
- Silence/non-response
- Voting results if applicable

## 8. KNOWLEDGE & INFORMATION GAPS

### 8.1 Explicit Gaps
**Definition**: Directly stated information needs
**Identification**: Pattern matching for:
- "We don't know..."
- "Need to find out..."
- "What's the status of...?" (unanswered)
- "We'll need to research..."

**Severity Classification**:
- **High**: Blocks decisions or critical path
- **Medium**: Important but not immediately blocking
- **Low**: Nice to have, not urgent

### 8.2 Implied Gaps
**Definition**: Information needs inferred from context
**Methodology**:
1. Identify incomplete discussions
2. Note questions raised without answers
3. Recognize areas of uncertainty or hesitation
4. Map to critical business needs

**Categories**:
- Strategic/competitive intelligence
- Operational details
- Financial projections
- Risk assessment
- Stakeholder requirements

### 8.3 Knowledge Coverage Assessment
**Status**: ⚠️ NEEDS BACKEND CATEGORIZATION

**Knowledge Domains**:
- Strategic Vision
- Operations & Processes
- Financial Planning
- Technology & Tools
- Market & Competition
- Team & Culture
- Legal & Compliance
- Customer/Stakeholder Needs

**Interpretation**:
- 85-100: Deep knowledge, high confidence
- 70-84: Good understanding, minor gaps
- 50-69: Moderate knowledge, significant uncertainty
- 30-49: Limited knowledge, many gaps
- 0-29: Very limited or no discussion

## 9. MEETING QUALITY ASSESSMENT

### 9.1 Signal vs. Noise
**Definitions**:
- **Signal**: On-topic, productive discussion
- **Noise**: Off-topic, redundant, or administrative talk

**Calculation**:
```
Signal % = (Signal utterances / Total utterances) × 100
Noise % = 100 - Signal %
```

**Threshold for Quality**: > 80% signal

## 10. POWER DYNAMICS

### 10.1 Power Language Distribution - DETAILED CALCULATION
**Status**: ⚠️ NEEDS PROPER BACKEND CALCULATION

**Categories**:

**High Power Language**:
- Commands: "Do this", "You need to"
- Directives: "Let's move on", "We should"
- Certainty: "Obviously", "Clearly"
- Interruptions (dominant)

**Low Power Language**:
- Questions: "What do you think?"
- Hedges: "Maybe", "Perhaps", "Could we"
- Qualifiers: "In my opinion", "I wonder if"
- Deference: "If you agree", "Does that make sense?"

**Neutral Language**:
- Factual statements
- Data presentation
- Process discussion

#### Pattern Library for Classification

```python
HIGH_POWER_PATTERNS = {
    'commands': [
        r'\b(do|make|create|get|take|give)\s+(this|that|it)\b',
        r'\byou\s+(need|must|should|have)\s+to\b',
        r'\b(just|simply|obviously|clearly)\s+\w+\b'
    ],
    'directives': [
        r'\blet\'?s\s+(move|go|get|do)\b',
        r'\bwe\s+(should|must|need\s+to|have\s+to)\b',
        r'\b(here\'?s\s+what|this\s+is\s+how)\b'
    ],
    'certainty': [
        r'\b(obviously|clearly|definitely|certainly|absolutely)\b',
        r'\bthere\'?s\s+no\s+(question|doubt)\b',
        r'\bwithout\s+a\s+doubt\b'
    ]
}

LOW_POWER_PATTERNS = {
    'questions': [
        r'\bwhat\s+do\s+you\s+think\b',
        r'\b(could|would|might)\s+we\b',
        r'\b(any\s+thoughts|your\s+perspective|input)\b'
    ],
    'hedges': [
        r'\b(maybe|perhaps|possibly|probably)\b',
        r'\b(sort\s+of|kind\s+of|I\s+guess)\b',
        r'\bmight\s+be\s+able\s+to\b'
    ],
    'qualifiers': [
        r'\bin\s+my\s+(opinion|view|perspective)\b',
        r'\bI\s+(think|feel|believe|wonder)\b',
        r'\bit\s+seems\s+(like|to\s+me)\b'
    ],
    'deference': [
        r'\bif\s+(you|everyone)\s+agree\b',
        r'\bdoes\s+that\s+make\s+sense\b',
        r'\bis\s+that\s+(okay|alright)\b'
    ]
}

NEUTRAL_PATTERNS = {
    'statements': [
        r'\b(the|this|that)\s+\w+\s+(is|was|will\s+be)\b',
        r'\baccording\s+to\b',
        r'\bdata\s+shows\b'
    ]
}
```

#### Calculation Steps

```python
def classify_power_language(utterance):
    high_power_count = 0
    low_power_count = 0
    
    # Check high power patterns
    for category, patterns in HIGH_POWER_PATTERNS.items():
        for pattern in patterns:
            if re.search(pattern, utterance, re.IGNORECASE):
                high_power_count += 1
    
    # Check low power patterns
    for category, patterns in LOW_POWER_PATTERNS.items():
        for pattern in patterns:
            if re.search(pattern, utterance, re.IGNORECASE):
                low_power_count += 1
    
    # Classify
    if high_power_count > low_power_count:
        return 'high'
    elif low_power_count > high_power_count:
        return 'low'
    else:
        return 'neutral'

def analyze_transcript_power_language(transcript):
    utterances = split_into_utterances(transcript)
    
    high_count = 0
    low_count = 0
    neutral_count = 0
    
    for utterance in utterances:
        classification = classify_power_language(utterance['text'])
        if classification == 'high':
            high_count += 1
        elif classification == 'low':
            low_count += 1
        else:
            neutral_count += 1
    
    total = len(utterances)
    
    return {
        'high_power_pct': (high_count / total) * 100,
        'low_power_pct': (low_count / total) * 100,
        'neutral_pct': (neutral_count / total) * 100
    }
```

**Output Format for Frontend**:
```json
{
    "overall": {
        "highPower": 16.3,
        "lowPower": 42.8,
        "neutral": 40.9
    },
    "by_speaker": {
        "Alex": {"highPower": 22, "lowPower": 31, "neutral": 47},
        "G": {"highPower": 19, "lowPower": 35, "neutral": 46},
        "Sudheer": {"highPower": 8, "lowPower": 58, "neutral": 34}
    }
}
```

**Interpretation**:
- High low-power language (>40%): Collaborative culture
- High high-power language (>30%): Hierarchical culture
- Balanced (20-30% each): Context-dependent leadership

### 10.2 Speaker Power Profiles
**Metric**: % of high-power vs. low-power language per speaker
**Calculation**: For each speaker:
```
High Power % = (High power utterances / Speaker's total utterances) × 100
Low Power % = (Low power utterances / Speaker's total utterances) × 100
```

## 11. EPISTEMIC AUTHORITY

### 11.1 Knowledge Control Analysis
**Definition**: Who the group defers to as domain experts
**Identification Methodology**:
1. Track when speakers ask someone specific for input
2. Note when group waits for someone's opinion before deciding
3. Observe trust without verification
4. Count explicit expertise references

**Calculation**:
```
Authority Score = Count of deference instances per person per domain
```

## 13. RELATIONAL HEALTH METRICS - DETAILED CALCULATION

**Status**: ⚠️ NEEDS TIMELINE CALCULATION

### 13.1 Trust
**Definition**: Expressions of confidence in others' competence and intentions

**Indicators to Track**:
```python
TRUST_INDICATORS = {
    'vulnerability_sharing': [
        r'\bI\s+don\'?t\s+know\b',
        r'\bI\'?m\s+(not\s+sure|uncertain|confused)\b',
        r'\bneed\s+help\s+with\b'
    ],
    'delegation': [
        r'\b(you\s+decide|your\s+call|trust\s+your\s+judgment)\b',
        r'\bI\'?ll\s+leave\s+that\s+to\s+you\b',
        r'\byou\'?re\s+the\s+expert\b'
    ],
    'accepting_expertise': [
        r'\bthat\s+makes\s+sense\b',
        r'\bI\s+trust\s+(that|you)\b',
        r'\bsounds\s+good\b'
    ]
}
```

### 13.2 Alignment
**Definition**: Agreement on goals, values, and direction

**Indicators to Track**:
```python
ALIGNMENT_INDICATORS = {
    'shared_language': [
        r'\bour\s+(mission|vision|goal|purpose)\b',
        r'\bwe\'?re\s+all\s+(trying|working|aiming)\b'
    ],
    'unified_purpose': [
        r'\btogether\s+we\b',
        r'\bsame\s+page\b'
    ]
}
```

### 13.3 Care
**Definition**: Concern for others' wellbeing and experience

**Indicators**:
```python
CARE_INDICATORS = {
    'checking_in': [
        r'\bhow\s+(are\s+you|is\s+everyone)\b',
        r'\bfeeling\s+okay\b'
    ],
    'acknowledging_feelings': [
        r'\bI\s+(hear|see|understand)\s+(that|how)\b',
        r'\bI\s+appreciate\s+(you|that)\b'
    ],
    'gratitude': [
        r'\bthank\s+you\b',
        r'\bgrateful\s+for\b'
    ]
}
```

### 13.4 Belonging
**Definition**: Sense of inclusion and membership

**Indicators**:
```python
BELONGING_INDICATORS = {
    'collective_identity': [
        r'\bwe\'?re\s+a\s+(team|tribe|family|community)\b',
        r'\btogether\b'
    ],
    'inclusion': [
        r'\ball\s+of\s+us\b',
        r'\beveryone\'?s\s+(voice|input|perspective)\b'
    ]
}
```

### 13.5 Complete Timeline Calculation
```python
def calculate_relational_health_timeline(transcript, interval_minutes=10):
    utterances = parse_transcript_with_timestamps(transcript)
    
    trust_data = calculate_trust_score(utterances, interval_minutes)
    alignment_data = calculate_alignment_score(utterances, interval_minutes)
    care_data = calculate_care_score(utterances, interval_minutes)
    belonging_data = calculate_belonging_score(utterances, interval_minutes)
    
    # Combine into single timeline
    timeline = []
    for i in range(len(trust_data)):
        timeline.append({
            'timeblock': trust_data[i]['time'],
            'trust': trust_data[i]['score'],
            'alignment': alignment_data[i]['score'],
            'care': care_data[i]['score'],
            'belonging': belonging_data[i]['score']
        })
    
    # Calculate overall averages
    avg_trust = sum([t['trust'] for t in timeline]) / len(timeline)
    avg_alignment = sum([t['alignment'] for t in timeline]) / len(timeline)
    avg_care = sum([t['care'] for t in timeline]) / len(timeline)
    avg_belonging = sum([t['belonging'] for t in timeline]) / len(timeline)
    
    return {
        'timeline': timeline,
        'averages': {
            'trust': round(avg_trust),
            'alignment': round(avg_alignment),
            'care': round(avg_care),
            'belonging': round(avg_belonging)
        }
    }
```

**Output Format for Frontend**:
```json
{
    "timeline": [
        {"timeblock": "0-10 min", "trust": 75, "alignment": 80, "care": 85, "belonging": 82},
        {"timeblock": "10-20 min", "trust": 78, "alignment": 82, "care": 87, "belonging": 85},
        {"timeblock": "20-30 min", "trust": 80, "alignment": 85, "care": 88, "belonging": 88}
    ],
    "averages": {
        "trust": 82,
        "alignment": 84,
        "care": 86,
        "belonging": 86
    }
}
```

## 14. EMOTIONAL DYNAMICS

### 14.1 Sentiment Analysis
**Methodology**: Natural Language Processing sentiment analysis
**Calculation**:
- Assign sentiment score to each utterance (1-5 scale)
- 1: Very negative
- 3: Neutral
- 5: Very positive

**Average Sentiment**:
```
Avg Sentiment = Sum of all utterance sentiments / Total utterances
```

**Timeline**: Plot sentiment over time (10-minute intervals)

### 14.2 Empathy Score
**Definition**: Frequency of empathetic behaviors
**Components**:

**Explicit Empathetic Statements**: "I understand how you feel", "That must be challenging"
**Feeling-Oriented Questions**: "How does that feel?", "What's your sense?"
**Active Listening/Validation**: "I hear you", "That makes sense", paraphrasing

**Calculation**:
```
Empathy Score = (Total empathy instances / Total utterances) × 100
```

**Thresholds**:
- > 20 per 100: High empathy
- 10-20 per 100: Moderate
- < 10 per 100: Low

## 15. BREAKTHROUGH MOMENTS

### 15.1 Classification System
**Four Types of Breakthroughs**:

**Cognitive Breakthroughs**: 
- New understanding or insight
- "Aha" moments
- Strategic clarity

**Emotional Breakthroughs**:
- Significant emotional shift
- Vulnerability moment
- Emotional connection

**Relational Breakthroughs**:
- Shift in group dynamics
- Conflict resolution
- Trust building

**Behavioral Breakthroughs**:
- New commitment to action
- Pattern interruption
- Decision to change behavior

### 15.2 Identification Methodology
**Indicators**:
- Language shift (before/after)
- Energy change (sentiment spike)
- Group response (multiple affirmations)
- Explicit naming ("This is a breakthrough")
- Decision or commitment following

## 16. CONVERSATION STRUCTURE & QUALITY

### 16.1 Convergence/Divergence Analysis
**Definitions**:
- **Divergence**: Exploring multiple perspectives, generating options
- **Convergence**: Narrowing focus, moving toward decision

**Healthy Pattern**: 
- Diverge → Converge pattern (V-shape)
- Divergence early, convergence later

### 16.2 Signal vs. Noise Timeline
**Granularity**: 10-minute intervals
**Calculation**: For each interval:
```
Signal % = (On-topic utterances / Total utterances in interval) × 100
Noise % = 100 - Signal %
```

## APPENDIX B: THRESHOLDS & BENCHMARKS

### Score Interpretations

| Metric | Excellent | Good | Moderate | Needs Work |
|--------|-----------|------|----------|------------|
| Engagement | 75-100 | 60-74 | 40-59 | 0-39 |
| Inclusion | 70-100 | 50-69 | 30-49 | 0-29 |
| Consensus | 80-100 | 60-79 | 40-59 | 0-39 |
| Signal/Noise | 85-100 | 70-84 | 50-69 | 0-49 |
| Empathy | 20+ | 15-19 | 10-14 | 0-9 |
| Relational Health | 80-100 | 65-79 | 50-64 | 0-49 |

### Meeting Duration Context
- **Short (< 30 min)**: Focus on efficiency metrics
- **Medium (30-90 min)**: Standard analysis
- **Long (90+ min)**: Add fatigue indicators, break analysis

================================================================================
USAGE NOTES FOR DEVELOPERS
================================================================================

1. **When updating LLM instructions**: Modify analysis-prompt.md and reference 
   the calculation sections from this combined file.

2. **When implementing metrics**: Use the calculation logic from the corresponding
   section. Follow the Python code examples provided.

3. **When tuning thresholds**: See Appendix B for interpretation benchmarks.
   Test against real meeting data to validate.

4. **When adding new metrics**: 
   - Document in "calculations_for_metrics.md"
   - Update "analysis-prompt.md" to include in JSON structure
   - Add implementation examples with Python code
   - Set implementation status (✅ or ⚠️)

5. **For frontend integration**:
   - Expected JSON structure is defined in analysis-prompt.md
   - Charts should consume metrics from this JSON
   - See "Charts Part 1 & 2" JavaScript for implementation examples

6. **Version Control**:
   - Version: 2.0 (November 2025)
   - Last Updated: November 19, 2025
   - Changes in v2.0: Added implementation status, detailed calculations, 
     pattern libraries, Python examples

================================================================================
END OF SYSTEM PROMPTS COMBINED FILE
================================================================================

